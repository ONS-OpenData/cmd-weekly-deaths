{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Data will be taken from spreadsheets or downloaded from url.\n",
      "Do you have the spreadsheets available? [Y/N]\n",
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Published_Week_24_2020.xlsx which has size 194898 bytes\n",
      "Table names: ['Analysis', 'Contents', 'Information', 'Terms and conditions', 'Weekly figures 2020', 'Covid-19 - Weekly registrations', 'Covid-19 - Weekly occurrences', 'UK - Covid-19 - Weekly reg', 'Covid-19 - E&W comparisons', 'Covid-19 - England comparisons', 'Covid-19 - Wales comparison', 'Covid-19 - Place of occurrence ', 'Related publications']\n",
      "TIMEUNIT='Year'\n",
      "TIMEUNIT='Year'\n",
      "TIMEUNIT='Year'\n",
      "Extracting data structured as v4.\n",
      "Quick comparison check on v4-weekly-deaths-regional.csv\n",
      "Difference between week numbers is not correct\n",
      "Previous week goes up to 24\n",
      "New week goes up to 24\n",
      "New and previous v4 have same length, are week numbers the same\n",
      "TIMEUNIT='Year'\n",
      "TIMEUNIT='Year'\n",
      "TIMEUNIT='Year'\n",
      "Extracting data structured as v4.\n",
      "Quick comparison check on v4-weekly-deaths-age-sex.csv\n",
      "Difference between week numbers is not correct\n",
      "Previous week goes up to 24\n",
      "New week goes up to 24\n",
      "New and previous v4 have same length, are week numbers the same\n",
      "SparsityFiller took 0:00:00.081263\n",
      "Quick comparison check on v4-weekly-deaths-health-board.csv\n",
      "All ok\n",
      "Quick comparison check on v4-weekly-deaths-local-authority.csv\n",
      "All ok\n",
      "Transforms complete!\n"
     ]
    }
   ],
   "source": [
    "import WDFunctions as w\n",
    "\n",
    "take_data_from_url = input('''\n",
    "Data will be taken from spreadsheets or downloaded from url.\n",
    "Do you have the spreadsheets available? [Y/N]\n",
    "''')\n",
    "\n",
    "if take_data_from_url.lower() == 'y':\n",
    "    import glob\n",
    "    location = '*' # path name to directory of files, * for current directory\n",
    "    files = glob.glob('*')\n",
    "    \n",
    "    file = [file for file in files if 'published' in file.lower()][0] #'publishedweek202020.xlsx'\n",
    "    tabs = w.loadxlstabs(file)\n",
    "    w.WeeklyDeathsByRegion(tabs)\n",
    "    w.WeeklyDeathsByAgeSex(tabs)\n",
    "\n",
    "    file = [file for file in files if 'lahb' in file] # 'lahbtablesweek20finalcodes.xlsx'\n",
    "    if len(file) == 0:\n",
    "        file = [file for file in files if 'la_hb' in file.lower()][0]\n",
    "    else: file = file[0]\n",
    "    reg_data = w.pd.read_excel(file, sheet_name='Registrations - All data', skiprows=3)\n",
    "    occ_data = w.pd.read_excel(file, sheet_name='Occurrences - All data', skiprows=3)\n",
    "    w.WeeklyDeathsByLA_HB(reg_data, occ_data, '2020')\n",
    "    \n",
    "    print('Transforms complete!')\n",
    "\n",
    "else:\n",
    "    print('Taking data from url download')\n",
    "    \n",
    "    from gssutils import *\n",
    "\n",
    "    # get weekly deaths data from url -> by regions & by sex and age\n",
    "    url = 'https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/weeklyprovisionalfiguresondeathsregisteredinenglandandwales'\n",
    "    scraper = Scraper(url)\n",
    "\n",
    "    # get required tabs -> passed to functions\n",
    "    tabs = scraper.distributions[0].as_databaker()\n",
    "\n",
    "    # get weekly deaths data from url -> by local authority & health board\n",
    "    url = 'https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/causesofdeath/datasets/deathregistrationsandoccurrencesbylocalauthorityandhealthboard'\n",
    "    scraper = Scraper(url)\n",
    "\n",
    "    # import tabs separately -> registrations & occurrences -> to pass to function\n",
    "    reg_data = scraper.distributions[0].as_pandas(sheet_name='Registrations - All data', skiprows=3)\n",
    "    occ_data = scraper.distributions[0].as_pandas(sheet_name='Occurrences - All data', skiprows=3)\n",
    "\n",
    "    # run functions\n",
    "    w.WeeklyDeathsByRegion(tabs)\n",
    "    w.WeeklyDeathsByAgeSex(tabs)\n",
    "    w.WeeklyDeathsByLA_HB(reg_data, occ_data, '2020')\n",
    "    \n",
    "    print('Transforms complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
